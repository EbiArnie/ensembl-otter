    Process of transferring otter_'species'
    database to loutre_'species' database
------------------------------------------------------------------
# UPDATE 

1) Make the loutre_'species' database on otterlive
with all the needed assemblies

1.1) attrib_type table: to make sure that we are using the most up-to-date
values from HEADCODE run:

ensembl-HEAD/misc-scripts/attribute_types/upload_attributes.pl \
    -host otterlive -user ottroot -port 3324 -pass xx -dbnames loutre_'species' \
    -file attrib_type.txt

1.2) Make a dump of the database so that we can
easily re-start transfer if needed.

2) otterlive is used for dumping and loading the
files.Create needed directories

	 ssh otterlive
	 cd /mysql/otter-live-master/otter/loutre_load/
	 mkdir 'species'
	 mkdir 'species'/genes
	 mkdir 'species'/contig_info

2.1) Make sure hidden sequence set gets a row in seq_region_attribe:
     
	SELECT sr.*
	  , sa.value
	FROM seq_region sr
	  , seq_region_attrib sa
	WHERE sr.seq_region_id = sa.seq_region_id
	  AND sa.attrib_type_id = 129
	  AND sa.value = 0;

If not use:

  ensembl-otter/scripts/lace/transfer_hidden_attribute -old_dataset otter_dset_name \
     -new_dataset loutre_dsname -code hidden -port 33999 -change

to patch the data. NOTE: omit "-change" to preview the changes that will be made.

2.2) Run Chao-Kung's script which creates a list
of the redundant gene_id's.

	ensembl-otter/scripts/lace/get_redundant_dbid_of_genesid \
		-ds 'species' > outfile

3) Dump genes from otter_'species', using the
redundant gene_id list.

3.1) In a bash shell run the following script:

  ensembl-otter/scripts/lace/dump_genes_by_assembly_types \
    -redunfile /nfs/team71/analysis/ck1/TMP/loutre_species_backup/redundant_'species'_gene_dbids_to_skip_for_newotter \
    -dataset 'species' >> dump_genes.out 2>> dump_error.log &

notes: dsn-name is the data source name pointing
to the otter_'species' database from which the
dump will be taken

dump_genes.out is a mixed format text-xml file
which is needed by the loading script

3.3) some sanity checks

tail dump_error.log you get the count of geneids not
dumped like:

  total gene db ids from otter_db: T   ( select count(*) from otter_'species'.gene)
  neglected R redundant ids            ( wc -l ~ck1/bin/otter/xml/redundant_'species'_gene_dbids_to_skip_for_newotter )
  Got D gene db ids to dump
  Dumped O gene db ids to output file  ( grep -c "<locus>" dump_genes.out )
  Failed to map: F                     ( grep -c "FAILED TO MAP" dump_error.log )

Just check that:

  D = O+F AND T = R+O+F
  
If not, check dump_error.log

Alternatively, to quickly see which gene dbid is not dumped, 
 Run 
 perl ~/bin/otter/check_missing_gene_db_id.pl -ds human \
 -redunfile ~/bin/otter/xml/redundant_human_gene_dbids_to_skip_for_newotter \
 -dumperr dump_error_human.log -limit xxx (highest dbid at the time of dump)


4) Take a dump of the loutre_'species' before
loading, incase something goes wrong:

  mysqldump --opt -u ottroot -p -P 3324 -h otterlive \
    loutre_'species' > loutre_'species'.dump

5) CHECK that translation_stable_id does not have a
unique key on (stable_id,version)

6) create a key 'last_gene_old_dbid' in meta table
which tracks of the last gene dbid dumped and
loaded , if this key does not exists already in
loutre_'species' database

  INSERT INTO meta (meta_key
        , meta_value)
  VALUES('last_gene_old_dbid'
        , 0)

7) load the dump_genes.out file to the
loutre_'species' database like,

  ensembl-otter/scripts/lace/load_new_otter -dataset ns_'species' \
     /mysql/otter-live-master/otter/loutre_load/'species'/genes/dump_genes.out \
    >> load_genes.log 2>> load_error.log

7.1)

  grep -c "as new gene dbid: and" load_genes.log

This gives a count of unchanged genes that were
rejected during the loading.

7.2)

  grep -c "EXCEPTION" load_error.log

This gives the gene ids rejected due to some sort
of exception and these genes have to be carefully
analysed. If the genes can be really neglected,
then the loading is complete. But if not see if a
separate loading of these genes will be okay. If
not the loading has to be repeated, for which the
database dump will be useful to begin loading
again

7.3)

  grep -c "did not get loaded due" load_error.log       

  Check for the reasons why they are not loaded.


# INSERT meta key for foreign gene stable ids
INSERT INTO meta VALUES (null, 'prefix.primary', 'LDR');


# PATCH modified time of unchanged transcripts

Run ensembl-otter/scripts/lace/patch_transcript_modified_time \
    -dataset loutre_dataset_name -port 33999 > outfile

grep "UPDATE" outfile | mysql -uottadmin -p********** -P3324 -hotterlive loutre_'species'

------------------------------------------------

8) Do the big switch:

8.1) Warn users that we are going to switch, and wait
for edit sessions to clear - lock tables will
become empty.

  Maybe we can lock all the otter sequence_sets?
  We think the system will still permit users to
  save open write-access sessions. (Leo's idea.)

8.2) Remove dataset entry for species from server.

8.3) Check again that there are no locks in otter.

8.4) Make an incremental dump of genes as in 3.1) above and load it.

8.5) Load contig_info (see contig_info_loutre_load.txt)

8.6) Load sequence notes.

8.7) Load assembly tags.

8.8) Load simple_features

8.9) Need to set the auto increment counter in the
stable ID pool tables to the last value used in
the otter db.

8.10) Change config of dataset to point at new schema
and switch dataset back on.


9) Celebrate.

------------------------------------------------




